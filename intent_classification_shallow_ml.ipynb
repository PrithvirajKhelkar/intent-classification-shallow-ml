{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPKaiiKrjD1nsMuMx8U/CU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrithvirajKhelkar/intent-classification-shallow-ml/blob/main/intent_classification_shallow_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import required libraries"
      ],
      "metadata": {
        "id": "PUVqDriBx0hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding"
      ],
      "metadata": {
        "id": "W1g9H08-x3s9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loads the train and test datasets from [here](https://www.kaggle.com/datasets/hassanamin/atis-airlinetravelinformationsystem)"
      ],
      "metadata": {
        "id": "bYzTKBNOyYyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('atis_intents_train.csv', names=['intent', 'query'])\n",
        "test_df = pd.read_csv('atis_intents_test.csv', names=['intent', 'query'])\n"
      ],
      "metadata": {
        "id": "QJpuGkHSypo2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text preprocessing:\n",
        "First downloading the list of stop words from NLTK library, initializing the PorterStemmer object from NLTK, and defining a preprocess() function to clean and normalize the text data. The preprocess() function performs the following operations:\n",
        "* Converts the text to lowercase.\n",
        "* Removes non-alphabetic characters using regular expressions.\n",
        "* Tokenizes the text into words.\n",
        "* Stems each word using PorterStemmer object.\n",
        "* Removes stop words.\n",
        "* Joins the remaining words into a string.\n",
        "* Finally, the preprocessed text is stored in a new column named \"preprocessed_text\" in both train and test dataframes."
      ],
      "metadata": {
        "id": "pK8M3zQ_0Jev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    words = text.split()\n",
        "    words = [ps.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "train_df['preprocessed_text'] = train_df['query'].apply(preprocess)\n",
        "test_df['preprocessed_text'] = test_df['query'].apply(preprocess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfzuWQiO0Ubj",
        "outputId": "a64506cc-e57d-4d53-ae4f-efde1a6604af"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* encode the target variable \"intent\" into numerical labels using the LabelEncoder() function from scikit-learn library.\n",
        "* The fit_transform() method is used on the training data to fit the encoder and transform the labels, and the transform() method is used on the test data to transform the labels using the fitted encoder."
      ],
      "metadata": {
        "id": "cBiU-XB920jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(train_df['intent'])\n",
        "y_test_encoded = le.transform(test_df['intent'])"
      ],
      "metadata": {
        "id": "z2sRZnCC2578"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* tokenize the preprocessed text data into sequences using the Tokenizer() function from Keras.\n",
        "* The num_words parameter is set to 5000, which means only the top 5000 most frequent words in the dataset will be kept and the rest will be discarded.\n",
        "* The fit_on_texts() method is used on the training data to fit the tokenizer, and the texts_to_sequences() method is used on both training and test data to convert the preprocessed text data into sequences of numerical indices based on the learned vocabulary from the training data."
      ],
      "metadata": {
        "id": "samuGOCW2-Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_df['preprocessed_text'])\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['preprocessed_text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['preprocessed_text'])"
      ],
      "metadata": {
        "id": "AENgUBim3F3q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jexbFjdg3J_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the sequences\n",
        "max_seq_len = 50\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_seq_len)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_seq_len)\n",
        "\n",
        "print('Shape of X_train_padded:', X_train_padded.shape)\n",
        "print('Shape of y_train_encoded:', y_train_encoded.shape)\n",
        "print('Shape of X_test_padded:', X_test_padded.shape)\n",
        "print('Shape of y_test_encoded:', y_test_encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol31shND3Rrk",
        "outputId": "4f2b28e3-7ff4-42f9-8404-20477a45fea5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_padded: (4834, 50)\n",
            "Shape of y_train_encoded: (4834,)\n",
            "Shape of X_test_padded: (800, 50)\n",
            "Shape of y_test_encoded: (800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_seq_len))\n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dense(units=21, activation='softmax'))"
      ],
      "metadata": {
        "id": "MMPpCX1c3TA2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7V1rU9nr3VzL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.fit(X_train_padded, y_train_encoded, validation_data=(X_test_padded, y_test_encoded), epochs=10, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzeo5lXo3Ypw",
        "outputId": "d6ae57c8-e43e-4041-caed-02525d8f1768"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "38/38 [==============================] - 8s 172ms/step - loss: 1.4123 - accuracy: 0.7327 - val_loss: 0.8700 - val_accuracy: 0.7900\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 5s 141ms/step - loss: 0.9515 - accuracy: 0.7584 - val_loss: 0.8307 - val_accuracy: 0.7900\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 6s 161ms/step - loss: 0.8037 - accuracy: 0.7687 - val_loss: 0.5580 - val_accuracy: 0.8375\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 6s 145ms/step - loss: 0.5469 - accuracy: 0.8612 - val_loss: 0.3435 - val_accuracy: 0.9000\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 6s 166ms/step - loss: 0.3681 - accuracy: 0.9001 - val_loss: 0.2694 - val_accuracy: 0.9225\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 6s 151ms/step - loss: 0.2674 - accuracy: 0.9214 - val_loss: 0.2194 - val_accuracy: 0.9400\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 6s 165ms/step - loss: 0.1944 - accuracy: 0.9427 - val_loss: 0.1801 - val_accuracy: 0.9362\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 6s 149ms/step - loss: 0.1469 - accuracy: 0.9576 - val_loss: 0.1453 - val_accuracy: 0.9488\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 6s 168ms/step - loss: 0.1132 - accuracy: 0.9677 - val_loss: 0.1351 - val_accuracy: 0.9500\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 6s 146ms/step - loss: 0.0901 - accuracy: 0.9746 - val_loss: 0.1378 - val_accuracy: 0.9525\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa7402c8b50>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model\n",
        "_, accuracy = model.evaluate(X_test_padded, y_test_encoded)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI-8XwnD3cam",
        "outputId": "0407f124-e9a6-4a01-f85c-a35b77b89085"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1378 - accuracy: 0.9525\n",
            "Accuracy: 0.9524999856948853\n"
          ]
        }
      ]
    }
  ]
}